{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK3: E-MAIL SPAM DETECTION PROJECT\n",
    "INTRODUCTION:\n",
    "Weâ€™ve all been the recipient of spam emails before. Spam mail, or junk mail, is a type of email\n",
    "that is sent to a massive number of users at one time, frequently containing cryptic\n",
    "messages, scams, or most dangerously, phishing content.\n",
    "In this Project, use Python to build an email spam detector. Then, use machine learning to\n",
    "train the spam detector to recognize and classify emails into spam and non-spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     v1                                                 v2 Unnamed: 2  \\\n",
       " 0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       " 1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       " 2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       " 3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       " 4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       " \n",
       "   Unnamed: 3 Unnamed: 4  \n",
       " 0        NaN        NaN  \n",
       " 1        NaN        NaN  \n",
       " 2        NaN        NaN  \n",
       " 3        NaN        NaN  \n",
       " 4        NaN        NaN  ,\n",
       " None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'C:\\\\Users\\\\User\\\\OneDrive\\\\Desktop\\\\ALISHBA\\\\extra-curiculums\\\\oasis_infobyte_offerLetter\\\\task3\\\\spam.csv'\n",
    "data = pd.read_csv(file_path, encoding='latin-1')\n",
    "data.head(), data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 5 columns:\n",
    "1. v1: This appears to be the label, with \"ham\" indicating non-spam and \"spam\" indicating spam.\n",
    "2. v2: This contains the actual email text.\n",
    "3. Unnamed: 2, 3, and 4: These columns have many missing values and seem irrelevant for our analysis.\n",
    "\n",
    "Now we will clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(label      0\n",
       " message    0\n",
       " dtype: int64,\n",
       " (5572, 2),\n",
       "    label                                            message\n",
       " 0      0  Go until jurong point, crazy.. Available only ...\n",
       " 1      0                      Ok lar... Joking wif u oni...\n",
       " 2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       " 3      0  U dun say so early hor... U c already then say...\n",
       " 4      0  Nah I don't think he goes to usf, he lives aro...)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned = data[['v1', 'v2']].rename(columns={'v1': 'label', 'v2': 'message'})\n",
    "data_cleaned['label'] = data_cleaned['label'].map({'spam': 1, 'ham': 0})\n",
    "data_cleaned.isnull().sum(),data_cleaned.shape, data_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, There are no missing values in the cleaned dataset. we can proceed to preprocess the text data by converting it into a numerical format using TF-IDF (Term Frequency-Inverse Document Frequency), and then split the data into training and test sets for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4457, 3000), (1115, 3000))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_cleaned['message'], data_cleaned['label'], test_size=0.2, random_state=42)\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=3000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "X_train_tfidf.shape, X_test_tfidf.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The email messages have been successfully converted into a numerical format using TF-IDF, resulting in a dataset with 3,000 features (words) for both the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97847533632287\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.98      1.00      0.99       965\n",
      "        Spam       1.00      0.84      0.91       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.92      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    "y_pred = nb_classifier.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=['Ham', 'Spam'])\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the breakdown of what the results were shown:\n",
    "Ham (non-spam):\n",
    "1. Precision: 0.98 (98% of the emails predicted as \"ham\" were actually ham)\n",
    "2. Recall: 1.00 (100% of the actual ham emails were correctly identified)\n",
    "3. F1-Score: 0.99 (mean of precision and recall)\n",
    "\n",
    "Spam:\n",
    "1. Precision: 1.00 (100% of the emails predicted as spam were truly spam)\n",
    "2. Recall: 0.84 (84% of the actual spam emails were correctly identified)\n",
    "3. F1-Score: 0.91"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
